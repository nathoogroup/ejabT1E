{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ejabT1E Package Overview\n",
    "\n",
    "## What It Is\n",
    "\n",
    "**ejabT1E** is an R package for detecting Type I errors in published NHST (Null Hypothesis Significance Testing) results using the *eJAB01* approximate objective Bayes factor.\n",
    "\n",
    "The core idea: if a result is statistically significant (p <= alpha) but the Bayes factor strongly supports H0 (eJAB01 > C*), that result is a **Bayes/NHST contradiction** -- a candidate Type I error.\n",
    "\n",
    "The package implements the full pipeline:\n",
    "1. Compute eJAB01 for each result\n",
    "2. Estimate the threshold C* via minimum-distance estimation\n",
    "3. Flag contradictions (p <= alpha AND eJAB > C*)\n",
    "4. Compute diagnostic U_i values (should be Unif(0,1) if assumptions hold)\n",
    "5. Produce a diagnostic QQ-plot\n",
    "6. Compute posterior P(T1E) for each candidate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Functions\n",
    "\n",
    "| Function | Purpose |\n",
    "|----------|--------|\n",
    "| `ejab01(p, n, q)` | Compute the eJAB01 Bayes factor |\n",
    "| `objective_C(C, p, ejab, up)` | Closed-form objective for C* estimation |\n",
    "| `estimate_Cstar(p, ejab, up, grid)` | Grid search for optimal C* |\n",
    "| `detect_type1(p, ejab, alpha, Cstar)` | Flag Bayes/NHST contradictions |\n",
    "| `diagnostic_U(p, n, q, alpha, Cstar)` | Compute diagnostic U_i values |\n",
    "| `diagnostic_qqplot(U)` | QQ-plot of U_i vs Unif(0,1) |\n",
    "| `posterior_t1e(p, ejab, alpha, all_objectives, grid)` | Posterior P(T1E) per result |\n",
    "| `ejab_pipeline(df, up, alpha, grid, plot)` | Full pipeline wrapper |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Function Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ejab01(p, n, q)`\n",
    "\n",
    "Computes the approximate objective Bayes factor (evidence for H0 over H1):\n",
    "\n",
    "$$\\text{eJAB01}_i = \\sqrt{n_i} \\cdot \\exp\\left( -\\frac{1}{2} \\cdot \\frac{n_i^{1/q_i} - 1}{n_i^{1/q_i}} \\cdot \\chi^2_{q_i, 1-p_i} \\right)$$\n",
    "\n",
    "- `p`: p-values (0 < p < 1)\n",
    "- `n`: sample sizes (must be > 1)\n",
    "- `q`: test dimensions (number of parameters under H1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Package code:\n",
    "ejab01 <- function(p, n, q) {\n",
    "  if (!all(p > 0 & p < 1)) stop(\"All p-values must be in (0, 1).\")\n",
    "  if (!all(n > 1)) stop(\"All sample sizes n must be > 1.\")\n",
    "  if (!all(q >= 1)) stop(\"All dimensions q must be >= 1.\")\n",
    "  sqrt(n) * exp(-0.5 * (n^(1/q) - 1) / n^(1/q) * qchisq(1 - p, df = q))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `objective_C(C, p, ejab, up)`\n",
    "\n",
    "The closed-form objective for estimating C*. Measures the integrated squared deviation between the empirical contradiction rate $\\hat{P}(\\alpha, C)$ and the theoretical T1E rate $\\alpha / u_p$:\n",
    "\n",
    "$$\\text{obj}(C) = \\sum_{j=1}^{J} (p_{(j+1)} - p_{(j)}) \\hat{P}(p_{(j)}, C)^2 \\;-\\; \\frac{1}{u_p N} \\sum_{j=1}^{J} \\xi_j^C (u_p^2 - p_{(j)}^2) \\;+\\; \\frac{u_p}{3}$$\n",
    "\n",
    "where:\n",
    "- $p_{(j)}$ are sorted unique p-values, $p_{(J+1)} = u_p$\n",
    "- $\\xi_j^C$ = number of results at $p_{(j)}$ with eJAB > C (\"multiplicities\")\n",
    "- $\\hat{P}(p_{(j)}, C) = \\frac{1}{N}\\sum_{k=1}^{j} \\xi_k^C$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Helper: compute multiplicities\n",
    "compute_xi <- function(p_sub, ejab_sub, p_unique, C) {\n",
    "  vapply(p_unique, function(pj) {\n",
    "    sum(p_sub == pj & ejab_sub > C)\n",
    "  }, numeric(1))\n",
    "}\n",
    "\n",
    "# Package code:\n",
    "objective_C <- function(C, p, ejab, up) {\n",
    "  idx <- p <= up\n",
    "  p_sub <- p[idx]; ejab_sub <- ejab[idx]; N <- length(p_sub)\n",
    "  if (N == 0) return(Inf)\n",
    "\n",
    "  p_unique <- sort(unique(p_sub))\n",
    "  xi_C <- compute_xi(p_sub, ejab_sub, p_unique, C)\n",
    "  Phat_vals <- cumsum(xi_C) / N\n",
    "  gaps <- diff(c(p_unique, up))\n",
    "\n",
    "  term1 <- sum(gaps * Phat_vals^2)                          # integral of Phat^2\n",
    "  term2 <- -sum(xi_C * (up^2 - p_unique^2)) / (up * N)     # cross term\n",
    "  term3 <- up / 3                                           # constant\n",
    "  term1 + term2 + term3\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `estimate_Cstar(p, ejab, up, grid)`\n",
    "\n",
    "Grid search over C in [1/3, 3] (200 points). Returns the minimizer C* and the full vector of objective values (used later for posterior computation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `detect_type1(p, ejab, alpha, Cstar)`\n",
    "\n",
    "Simple logical detection: a result is a candidate T1E if $p_i \\le \\alpha$ AND $\\text{eJAB}_i > C^*$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `diagnostic_U(p, n, q, alpha, Cstar)`\n",
    "\n",
    "For each candidate T1E, computes:\n",
    "\n",
    "$$U_i = \\frac{p_i - d_i}{\\alpha - d_i}$$\n",
    "\n",
    "where:\n",
    "\n",
    "$$d_i = 1 - F_{\\chi^2_{q_i}}\\left( \\frac{2 n_i^{1/q_i}}{n_i^{1/q_i} - 1} \\log\\frac{\\sqrt{n_i}}{C^*} \\right)$$\n",
    "\n",
    "Under the left-tail uniformity assumption, $U_i \\sim \\text{Unif}(0,1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Package code:\n",
    "diagnostic_U <- function(p, n, q, alpha, Cstar) {\n",
    "  if (any(n <= 1)) stop(\"Sample sizes n must be > 1 for diagnostic computation.\")\n",
    "  d <- 1 - pchisq(\n",
    "    (2 * n^(1/q) / (n^(1/q) - 1)) * log(sqrt(n) / Cstar),\n",
    "    df = q\n",
    "  )\n",
    "  (p - d) / (alpha - d)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `posterior_t1e(p, ejab, alpha, all_objectives, grid)`\n",
    "\n",
    "Treats the objective as a negative log-likelihood. Under a uniform prior on C:\n",
    "\n",
    "$$\\pi(C_k \\mid \\text{data}) \\propto \\exp\\{-\\text{obj}(C_k)\\}$$\n",
    "\n",
    "For each result $i$, the posterior probability of being a T1E is:\n",
    "\n",
    "$$P(\\text{T1E}_i) = \\sum_{k:\\, p_i \\le \\alpha,\\; \\text{eJAB}_i > C_k} \\pi(C_k \\mid \\text{data})$$\n",
    "\n",
    "This sums posterior mass over all C values where that result would be flagged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ejab_pipeline(df, up, alpha, grid, plot)`\n",
    "\n",
    "Full wrapper. Expects a data frame with columns `p`, `n`, `q` (and optional `ID`). Runs all steps and returns C*, candidates with posterior probabilities, diagnostics, and the posterior over C.\n",
    "\n",
    "Input validation:\n",
    "- `alpha <= up` (required by theory)\n",
    "- `n > 1` (required by diagnostic formula)\n",
    "- Required columns exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Changes from `newMethod.R`\n",
    "\n",
    "The package was rewritten from the original `newMethod.R` prototype to fix mathematical errors and add missing functionality. Below is a detailed comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. `ejab01` -- Minor Fix\n",
    "\n",
    "The exponent term was missing a division by $n^{1/q}$.\n",
    "\n",
    "| | Expression |\n",
    "|---|---|\n",
    "| **Original** | `exp(-0.5 * (n^(1/q) - 1) * chi_quant)` |\n",
    "| **Corrected** | `exp(-0.5 * (n^(1/q) - 1) / n^(1/q) * chi_quant)` |\n",
    "\n",
    "The correct formula has $\\frac{n^{1/q} - 1}{n^{1/q}}$ not just $(n^{1/q} - 1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ORIGINAL (newMethod.R):\n",
    "# sqrt(n) * exp(-0.5 * (n^(1/q) - 1) * chi_quant)\n",
    "\n",
    "# CORRECTED (Package):\n",
    "# sqrt(n) * exp(-0.5 * (n^(1/q) - 1) / n^(1/q) * qchisq(1 - p, df = q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. `objective_C` -- Major Rewrite\n",
    "\n",
    "The original used an **unweighted pointwise sum** of squared differences, which does not match the closed-form integrated objective from the theory.\n",
    "\n",
    "**Original approach** (wrong):\n",
    "- Looped over unique p-values, computing `phat(...)` at each\n",
    "- Accumulated `(phat - alpha/up)^2` with no gap weighting\n",
    "- This is a Riemann sum with equal weights -- incorrect because the p-value spacing is non-uniform\n",
    "\n",
    "**Corrected approach:**\n",
    "- Computes multiplicities $\\xi_j^C$ (count of results at each unique p-value with eJAB > C)\n",
    "- Uses the closed-form with gap-weighted $\\hat{P}^2$ term, cross term using $(u_p^2 - p_{(j)}^2)$, and constant $u_p/3$\n",
    "- Properly reflects the integral $\\int_0^{u_p} [\\hat{P}(\\alpha, C) - \\alpha/u_p]^2 \\, d\\alpha$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ORIGINAL (newMethod.R):\n",
    "# objective_C <- function(C, p, ejab, up) {\n",
    "#   p_sub <- p[p <= up]\n",
    "#   p_grid <- sort(unique(p_sub))\n",
    "#   obj <- 0\n",
    "#   for (j in seq_along(p_grid)) {\n",
    "#     alpha <- p_grid[j]\n",
    "#     ph <- phat(p, ejab, alpha, C, up)\n",
    "#     obj <- obj + (ph - alpha / up)^2     <-- unweighted sum, wrong\n",
    "#   }\n",
    "#   obj\n",
    "# }\n",
    "\n",
    "# CORRECTED: uses closed-form with gap weighting, multiplicities, cross term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. `diagnostic_U` -- Sign Error in Log\n",
    "\n",
    "The `d_i` computation had `log(sqrt(n) * Cstar)` (multiplication) instead of `log(sqrt(n) / Cstar)` (division).\n",
    "\n",
    "| | Expression inside log |\n",
    "|---|---|\n",
    "| **Original** | `log(sqrt(ni) * Cstar)` |\n",
    "| **Corrected** | `log(sqrt(n) / Cstar)` |\n",
    "\n",
    "This corresponds to the theory: $d_i = 1 - F_{\\chi^2_q}\\left(\\frac{2n^{1/q}}{n^{1/q}-1} \\log\\frac{\\sqrt{n}}{C^*}\\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ORIGINAL (newMethod.R):\n",
    "# (2 * ni^(1/qi) / (ni^(1/qi) - 1)) * log(sqrt(ni) * Cstar)   <-- WRONG: multiply\n",
    "\n",
    "# CORRECTED (Package):\n",
    "# (2 * n^(1/q) / (n^(1/q) - 1)) * log(sqrt(n) / Cstar)        <-- CORRECT: divide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Grid Range -- Updated\n",
    "\n",
    "| | Grid |\n",
    "|---|---|\n",
    "| **Original** | `seq(1, 3, length.out = 200)` |\n",
    "| **Corrected** | `seq(1/3, 3, length.out = 200)` |\n",
    "\n",
    "The lower bound was changed from 1 to 1/3 per discussion with Dr. Nathoo (Jan 16), to provide better sensitivity at low effect sizes where C* < 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. New Functionality (Not in Original)\n",
    "\n",
    "| Feature | Description |\n",
    "|---------|-------------|\n",
    "| `posterior_t1e()` | Computes P(T1E) for each candidate by treating C* as a posterior mode |\n",
    "| `diagnostic_qqplot()` | QQ-plot of U_i vs Unif(0,1) |\n",
    "| Input validation | Guards for `p in (0,1)`, `n > 1`, `q >= 1`, `alpha <= up` |\n",
    "| `all_objectives` in output | Returns full objective vector for posterior computation |\n",
    "| `posterior_C` in output | Returns posterior distribution over C grid |\n",
    "| ID column preservation | Pipeline preserves optional `ID` column in candidates output |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Structural / Engineering Changes\n",
    "\n",
    "| Aspect | Original | Package |\n",
    "|--------|----------|--------|\n",
    "| Format | Single script file | Proper R package (DESCRIPTION, NAMESPACE, man/, tests/) |\n",
    "| Column name | `df$N` (capital) | `df$n` (lowercase, consistent with function args) |\n",
    "| Vectorization | `sapply` loop in `diagnostic_U` | Fully vectorized |\n",
    "| Documentation | None | Roxygen-style comments + .Rd man pages |\n",
    "| Tests | None | 8 unit tests in `tests/test_ejab.R` |\n",
    "| CRAN | N/A | Passes `R CMD check` with Status: OK |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary of Bug Impact\n",
    "\n",
    "1. **ejab01 exponent**: Missing `/n^(1/q)` would overstate the Bayes factor for large n, causing fewer detections than appropriate.\n",
    "\n",
    "2. **objective_C unweighted sum**: Would produce a biased C* estimate. The correct closed-form accounts for non-uniform p-value spacing via gap weighting.\n",
    "\n",
    "3. **diagnostic_U multiply vs divide**: With `*` instead of `/`, $d_i$ would be computed at the wrong chi-squared quantile, invalidating the Unif(0,1) calibration check entirely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Usage Example\n",
    "\n",
    "```r\n",
    "library(ejabT1E)\n",
    "\n",
    "df <- data.frame(\n",
    "  ID = 1:100,\n",
    "  p = runif(100, 0, 0.05),\n",
    "  n = sample(20:200, 100, replace = TRUE),\n",
    "  q = rep(1, 100)\n",
    ")\n",
    "\n",
    "result <- ejab_pipeline(df, up = 0.05, alpha = 0.05)\n",
    "\n",
    "result$Cstar                    # estimated threshold\n",
    "result$candidates               # flagged T1Es with posterior probs\n",
    "result$posterior_C              # posterior distribution over C\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] Double check the funding ($1250) and scholarship, this is of SC(something? data analysis)\n",
    "- [ ] Hackathon: Check airfare!!! Check dates! Etc.\n",
    "- [ ] Add R oxygen to package folder\n",
    "- R package:\n",
    "  - Minimizer: Make the search space from 0-10\n",
    "  - In sim studies, we want to demonstrate the method works & investigate how good $C^*$ is relative to $1$\n",
    "  - Thus we should compare $1$ and the AVG $C^*$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### posterior_t1e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUestion: What' the prior probability of a T1E?\n",
    "- It is .05\n",
    "\n",
    "We put a uniform prior on C; we dont know if its good or nor\n",
    "- We can potentially test like this:\n",
    "  - We get a posterior\n",
    "  - Add posterior corresponding to values of $C$ that make us declare a T1E\n",
    "  - What if we did this with the prior as well?\n",
    "    - Grid of $C$ values\n",
    "      - 5 of which ejab is greater than\n",
    "      - Add posterior prob of those 5 to get posterior prob of a t1e (this is what it does)\n",
    "    - Then: Sum over all C's on grid where p \\leq apha and ejab > C\n",
    "      - This sum is the posterior prob\n",
    "    - For the same C's, sum the prior probabilities (1/k)\n",
    "      - Can we turn this into a bayes factor?\n",
    "  - The issue being conidere ia that we have done normalizaiton to get probabilities which assumes a uniform prior - is this a good idea? What effect does it have on results?\n",
    "  - How should alpha (the prior probability) come into the answer? How do we get a posterior from this?\n",
    "- Prof assumes probabilities will increase "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ROC curves before were great: We will do same, but with C=1 and C^*\n",
    "- In a more realistic simulation:\n",
    "  - Randomly draw es\n",
    "  - Randomly draw sample size\n",
    "  - Incorporate selection process\n",
    "    - Only retain smaller p-values\n",
    "      - All p-values less than .05 are retained/kept\n",
    "      - p-values greater than .05 are almost never included; diminish w size of p-value\n",
    "      - Keep p-val in sample w a probability 1-p\n",
    "- Keep it simple: \n",
    "  - Instead of randomly generating es, ss, the only thing we add is a selection process\n",
    "- We will do a set of sims with a selection process, and one without\n",
    "  - Should we do it for everything? (Yes!)\n",
    "  - T-tetss first. Then all from original paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "name": "R"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
